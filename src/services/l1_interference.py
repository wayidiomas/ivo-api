# src/services/l1_interference.py
"""
Servi√ßo especializado em an√°lise e preven√ß√£o de interfer√™ncia L1‚ÜíL2 (portugu√™s‚Üíingl√™s).
Implementa√ß√£o das estrat√©gias GRAMMAR 2 do IVO V2 Guide usando IA para todas as verifica√ß√µes.
"""

import json
import logging
import time
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime

from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
from pydantic import BaseModel, ValidationError

from src.core.unit_models import (
    GrammarContent, VocabularyItem, L1InterferencePattern,
    CommonMistake, ContrastiveExample
)
from src.core.enums import CEFRLevel, LanguageVariant
from config.models import get_openai_config

logger = logging.getLogger(__name__)


class L1InterferenceAnalyzer:
    """Analisador de interfer√™ncia L1 (portugu√™s) no aprendizado de ingl√™s usando IA."""
    
    def __init__(self):
        """Inicializar com configura√ß√µes de IA."""
        self.openai_config = get_openai_config()
        
        # NOVO: Usar model_selector para obter o modelo correto
        from src.services.model_selector import get_llm_config_for_service
        
        # Obter configura√ß√£o espec√≠fica para l1_interference (TIER-3: o3-mini)
        llm_config = get_llm_config_for_service("l1_interference")
        self.llm = ChatOpenAI(**llm_config)
        
        # Cache de an√°lises recentes
        self._analysis_cache: Dict[str, Any] = {}
        self._max_cache_size = 50
        
        logger.info("‚úÖ L1InterferenceAnalyzer inicializado com IA")

    def _create_main_interference_schema(self) -> Dict[str, Any]:
        """Schema for main L1 interference analysis using structured output."""
        return {
            "title": "L1InterferenceAnalysis",
            "description": "Schema for L1 (Portuguese) to L2 (English) interference analysis",
            "type": "object",
            "properties": {
                "interference_patterns": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "category": {
                                "type": "string",
                                "enum": ["grammatical_structure", "word_order", "article_usage", "verb_construction", "preposition_usage", "false_cognates", "pronunciation_transfer", "semantic_differences"],
                                "description": "Category of interference pattern"
                            },
                            "portuguese_pattern": {"type": "string"},
                            "incorrect_english_transfer": {"type": "string"},
                            "correct_english": {"type": "string"},
                            "explanation": {"type": "string"},
                            "prevention_technique": {"type": "string"},
                            "example_context": {"type": "string"},
                            "difficulty_level": {"type": "string"},
                            "frequency": {"type": "string"}
                        },
                        "required": ["category", "portuguese_pattern", "incorrect_english_transfer", "correct_english", "explanation", "prevention_technique"],
                        "additionalProperties": False
                    },
                    "minItems": 1
                },
                "predicted_common_mistakes": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "mistake": {"type": "string"},
                            "correction": {"type": "string"},
                            "reason": {"type": "string"}
                        },
                        "required": ["mistake", "correction", "reason"],
                        "additionalProperties": False
                    }
                },
                "contrastive_examples": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "portuguese": {"type": "string"},
                            "english_wrong": {"type": "string"},
                            "english_correct": {"type": "string"},
                            "teaching_point": {"type": "string"}
                        },
                        "required": ["portuguese", "english_wrong", "english_correct", "teaching_point"],
                        "additionalProperties": False
                    }
                },
                "prevention_strategies": {
                    "type": "array",
                    "items": {"type": "string"},
                    "minItems": 1
                },
                "confidence_score": {
                    "type": "number",
                    "minimum": 0.0,
                    "maximum": 1.0
                }
            },
            "required": ["interference_patterns", "predicted_common_mistakes", "contrastive_examples", "prevention_strategies", "confidence_score"],
            "additionalProperties": False
        }

    def _create_vocabulary_interference_schema(self) -> Dict[str, Any]:
        """Schema for vocabulary L1 interference analysis."""
        return {
            "title": "VocabularyInterferenceAnalysis",
            "description": "Schema for vocabulary L1 interference analysis",
            "type": "object",
            "properties": {
                "vocabulary_interference_items": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "word": {"type": "string"},
                            "interference_type": {
                                "type": "string",
                                "enum": ["false_friend", "usage_difference", "semantic_difference", "collocation_issue"]
                            },
                            "portuguese_confusion": {"type": "string"},
                            "actual_english_meaning": {"type": "string"},
                            "common_mistake": {"type": "string"},
                            "correct_usage": {"type": "string"},
                            "teaching_strategy": {"type": "string"},
                            "examples": {
                                "type": "object",
                                "properties": {
                                    "wrong": {"type": "string"},
                                    "correct": {"type": "string"}
                                },
                                "required": ["wrong", "correct"]
                            },
                            "severity": {
                                "type": "string",
                                "enum": ["high", "medium", "low"]
                            }
                        },
                        "required": ["word", "interference_type", "portuguese_confusion", "actual_english_meaning", "common_mistake", "correct_usage", "teaching_strategy", "examples", "severity"]
                    }
                },
                "overall_interference_level": {"type": "string"},
                "teaching_priority": {
                    "type": "array",
                    "items": {"type": "string"}
                },
                "prevention_focus": {"type": "string"}
            },
            "required": ["vocabulary_interference_items", "overall_interference_level", "teaching_priority", "prevention_focus"],
            "additionalProperties": False
        }

    def _create_pronunciation_interference_schema(self) -> Dict[str, Any]:
        """Schema for pronunciation L1 interference analysis."""
        return {
            "title": "PronunciationInterferenceAnalysis",
            "description": "Schema for pronunciation L1 interference analysis",
            "type": "object",
            "properties": {
                "pronunciation_challenges": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "sound_category": {
                                "type": "string",
                                "enum": ["vowel", "consonant", "consonant_cluster", "stress_pattern", "rhythm", "intonation"]
                            },
                            "specific_sound": {"type": "string"},
                            "portuguese_interference": {"type": "string"},
                            "correct_english": {"type": "string"},
                            "difficulty_level": {
                                "type": "string",
                                "enum": ["high", "medium", "low"]
                            },
                            "teaching_technique": {"type": "string"},
                            "practice_words": {
                                "type": "array",
                                "items": {"type": "string"}
                            }
                        },
                        "required": ["sound_category", "specific_sound", "portuguese_interference", "correct_english", "difficulty_level", "teaching_technique"]
                    }
                },
                "overall_pronunciation_difficulty": {"type": "string"},
                "priority_sounds": {
                    "type": "array",
                    "items": {"type": "string"}
                },
                "suggested_practice_sequence": {
                    "type": "array",
                    "items": {"type": "string"}
                }
            },
            "required": ["pronunciation_challenges", "overall_pronunciation_difficulty", "priority_sounds", "suggested_practice_sequence"],
            "additionalProperties": False
        }
    
    async def analyze_content_for_l1_interference(
        self,
        grammar_point: str,
        vocabulary_items: List[VocabularyItem],
        cefr_level: str,
        unit_context: str,
        language_variant: str = "american_english"
    ) -> Dict[str, Any]:
        """
        Analisar conte√∫do da unidade para identificar interfer√™ncias L1 usando IA.
        
        Args:
            grammar_point: Ponto gramatical principal da unidade
            vocabulary_items: Lista de vocabul√°rio da unidade
            cefr_level: N√≠vel CEFR da unidade
            unit_context: Contexto tem√°tico da unidade
            language_variant: Variante do ingl√™s (american/british)
            
        Returns:
            Dict com an√°lise completa de interfer√™ncias L1‚ÜíL2
        """
        try:
            logger.info(f"üîç Analisando interfer√™ncia L1‚ÜíL2 via IA: {grammar_point}")
            
            # Cache key para evitar reprocessamento
            cache_key = self._generate_cache_key(
                grammar_point, vocabulary_items, cefr_level, unit_context
            )
            
            cached_result = self._get_from_cache(cache_key)
            if cached_result:
                logger.info("üì¶ Usando an√°lise L1 do cache")
                return cached_result
            
            # 1. An√°lise principal de interfer√™ncia via IA
            main_analysis = await self._analyze_main_interference_patterns(
                grammar_point, vocabulary_items, cefr_level, unit_context, language_variant
            )
            
            # 2. An√°lise espec√≠fica de vocabul√°rio via IA
            vocabulary_analysis = await self._analyze_vocabulary_interference_ai(
                vocabulary_items, cefr_level, unit_context, language_variant
            )
            
            # 3. An√°lise de pron√∫ncia via IA
            pronunciation_analysis = await self._analyze_pronunciation_interference_ai(
                vocabulary_items, cefr_level, language_variant
            )
            
            # 4. Gera√ß√£o de exerc√≠cios preventivos via IA
            preventive_exercises = await self._generate_preventive_exercises_ai(
                main_analysis, vocabulary_analysis, pronunciation_analysis, cefr_level
            )
            
            # 5. Recomenda√ß√µes pedag√≥gicas via IA
            teaching_recommendations = await self._generate_teaching_recommendations_ai(
                grammar_point, main_analysis, cefr_level, unit_context
            )
            
            # 6. Compilar an√°lise final
            l1_analysis = {
                "grammar_point": grammar_point,
                "cefr_level": cefr_level,
                "unit_context": unit_context,
                "language_variant": language_variant,
                "main_interference_patterns": main_analysis,
                "vocabulary_interference": vocabulary_analysis,
                "pronunciation_interference": pronunciation_analysis,
                "preventive_exercises": preventive_exercises,
                "teaching_recommendations": teaching_recommendations,
                "common_mistakes": main_analysis.get("predicted_common_mistakes", []),
                "contrastive_examples": main_analysis.get("contrastive_examples", []),
                "prevention_strategies": main_analysis.get("prevention_strategies", []),
                "difficulty_assessment": await self._assess_difficulty_level_ai(
                    grammar_point, vocabulary_items, cefr_level
                ),
                "brazilian_specific_focus": True,
                "analysis_timestamp": datetime.now().isoformat(),
                "ai_confidence_score": main_analysis.get("confidence_score", 0.85)
            }
            
            # Salvar no cache
            self._save_to_cache(cache_key, l1_analysis)
            
            logger.info(f"‚úÖ An√°lise L1‚ÜíL2 conclu√≠da via IA com {len(main_analysis.get('interference_patterns', []))} padr√µes")
            
            return l1_analysis
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise de interfer√™ncia L1 via IA: {str(e)}")
            raise
    
    async def _analyze_main_interference_patterns(
        self,
        grammar_point: str,
        vocabulary_items: List[VocabularyItem],
        cefr_level: str,
        unit_context: str,
        language_variant: str
    ) -> Dict[str, Any]:
        """An√°lise principal de padr√µes de interfer√™ncia via IA."""
        
        vocabulary_words = [item.word for item in vocabulary_items]
        vocabulary_examples = [f"{item.word}: {item.example}" for item in vocabulary_items[:8]]
        
        system_prompt = """You are a world-class expert in Second Language Acquisition, specializing in L1 interference analysis for Brazilian Portuguese speakers learning English.

Your expertise includes:
- Contrastive analysis between Portuguese and English
- Common error patterns of Brazilian learners
- Pedagogical strategies for interference prevention
- CEFR-appropriate difficulty assessment

Analyze content for specific L1 (Portuguese) ‚Üí L2 (English) interference patterns that Brazilian learners are likely to encounter."""

        human_prompt = f"""Analyze this English lesson content for L1 interference from Brazilian Portuguese:

LESSON DETAILS:
- Grammar Point: {grammar_point}
- CEFR Level: {cefr_level}
- Context Theme: {unit_context}
- English Variant: {language_variant}

VOCABULARY IN LESSON:
{chr(10).join(vocabulary_examples)}

ANALYSIS REQUIRED:
Identify specific Portuguese‚ÜíEnglish interference patterns that Brazilian students will likely encounter with this content.

For each interference pattern, provide:
1. The Portuguese linguistic structure/habit
2. How it incorrectly transfers to English
3. The correct English form
4. Clear explanation of the difference
5. Practical prevention technique

FOCUS AREAS TO ANALYZE:
- Grammatical structure differences
- Word order patterns
- Article usage patterns
- Verb construction differences
- Preposition usage
- False cognates/friends
- Pronunciation transfer
- Semantic differences

Return detailed analysis in JSON format:
{{
  "interference_patterns": [
    {{
      "category": "grammatical_structure",
      "portuguese_pattern": "specific Portuguese structure",
      "incorrect_english_transfer": "how Brazilians incorrectly say it",
      "correct_english": "proper English form",
      "explanation": "why this happens and how they differ",
      "prevention_technique": "specific teaching strategy",
      "example_context": "example using lesson vocabulary",
      "difficulty_level": "how hard this is for {cefr_level}",
      "frequency": "how often this error occurs"
    }}
  ],
  "predicted_common_mistakes": [
    {{
      "mistake": "specific error students will make",
      "correction": "how to fix it",
      "reason": "why Brazilians make this mistake"
    }}
  ],
  "contrastive_examples": [
    {{
      "portuguese": "Portuguese version",
      "english_wrong": "literal translation (wrong)",
      "english_correct": "proper English",
      "teaching_point": "what to emphasize"
    }}
  ],
  "prevention_strategies": [
    "specific strategy 1 for this content",
    "specific strategy 2 for this content"
  ],
  "confidence_score": 0.95
}}

Be specific to the actual content provided. Avoid generic advice."""

        try:
            # Usar structured output para garantir formato correto
            interference_schema = self._create_main_interference_schema()
            structured_llm = self.llm.with_structured_output(interference_schema)
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            logger.info("ü§ñ Consultando IA para an√°lise L1 interference com structured output...")
            analysis = await structured_llm.ainvoke(messages)
            
            # Validar que retornou dict
            if not isinstance(analysis, dict):
                logger.warning("‚ö†Ô∏è Structured output n√£o retornou dict, convertendo...")
                analysis = dict(analysis) if hasattr(analysis, '__dict__') else {}
            
            # Garantir campos obrigat√≥rios com fallbacks seguros
            analysis = self._ensure_main_analysis_fields(analysis)
            
            logger.info(f"‚úÖ An√°lise principal L1 via structured output: {len(analysis.get('interference_patterns', []))} padr√µes")
            return analysis
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise L1 com structured output: {str(e)}")
            logger.info("üîÑ Tentando fallback sem structured output...")
            return await self._fallback_main_analysis_without_structured(grammar_point, vocabulary_words, cefr_level, system_prompt, human_prompt)

    def _ensure_main_analysis_fields(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Garantir campos obrigat√≥rios com fallbacks seguros."""
        defaults = {
            "interference_patterns": [],
            "predicted_common_mistakes": [],
            "contrastive_examples": [],
            "prevention_strategies": ["Pr√°tica regular e corre√ß√£o consciente"],
            "confidence_score": 0.85
        }
        
        for field, default_value in defaults.items():
            if not analysis.get(field):
                analysis[field] = default_value
        
        return analysis

    async def _fallback_main_analysis_without_structured(
        self, 
        grammar_point: str, 
        vocabulary_words: List[str], 
        cefr_level: str, 
        system_prompt: str, 
        human_prompt: str
    ) -> Dict[str, Any]:
        """Fallback sem structured output quando structured falha."""
        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            content = response.content
            
            # Parse resposta JSON manual
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].strip()
            
            analysis = json.loads(content)
            
            # Aplicar limpeza rigorosa no fallback
            analysis = self._ensure_main_analysis_fields(analysis)
            
            logger.info(f"‚úÖ Fallback an√°lise L1 manual: {len(analysis.get('interference_patterns', []))} padr√µes")
            return analysis
            
        except (json.JSONDecodeError, ValueError) as e:
            logger.warning(f"‚ö†Ô∏è Erro no fallback JSON: {str(e)}")
            return await self._fallback_main_analysis(grammar_point, vocabulary_words, cefr_level)
        except Exception as e:
            logger.error(f"‚ùå Erro no fallback: {str(e)}")
            return await self._fallback_main_analysis(grammar_point, vocabulary_words, cefr_level)

    def _ensure_vocabulary_analysis_fields(self, analysis: Dict[str, Any], vocabulary_items: List[VocabularyItem]) -> Dict[str, Any]:
        """Garantir campos obrigat√≥rios da an√°lise de vocabul√°rio."""
        defaults = {
            "vocabulary_interference_items": [],
            "overall_interference_level": "medium",
            "teaching_priority": [item.word for item in vocabulary_items[:3]],
            "prevention_focus": "general_awareness"
        }
        
        for field, default_value in defaults.items():
            if not analysis.get(field):
                analysis[field] = default_value
        
        return analysis
    
    async def _analyze_vocabulary_interference_ai(
        self,
        vocabulary_items: List[VocabularyItem],
        cefr_level: str,
        unit_context: str,
        language_variant: str
    ) -> Dict[str, Any]:
        """An√°lise espec√≠fica de interfer√™ncia de vocabul√°rio via IA."""
        
        vocabulary_details = []
        for item in vocabulary_items:
            vocab_detail = f"Word: {item.word}"
            if item.definition:
                vocab_detail += f" | Portuguese: {item.definition}"
            if item.example:
                vocab_detail += f" | Example: {item.example}"
            if item.word_class:
                vocab_detail += f" | Class: {item.word_class}"
            vocabulary_details.append(vocab_detail)
        
        system_prompt = """You are an expert in lexical interference analysis for Brazilian Portuguese speakers learning English.

Analyze vocabulary for specific L1 interference issues including:
- False friends/cognates
- Semantic differences
- Usage pattern differences
- Collocation differences
- Register differences
- Cultural concept differences"""

        human_prompt = f"""Analyze this vocabulary list for L1 interference from Brazilian Portuguese:

VOCABULARY TO ANALYZE:
{chr(10).join(vocabulary_details)}

CONTEXT: {unit_context}
LEVEL: {cefr_level}
VARIANT: {language_variant}

For each word that has potential L1 interference, identify:
1. Type of interference (false friend, usage difference, etc.)
2. How Brazilians might misuse it
3. Correct usage in English
4. Prevention/teaching strategy

Return analysis in JSON:
{{
  "vocabulary_interference_items": [
    {{
      "word": "vocabulary word",
      "interference_type": "false_friend|usage_difference|semantic_difference|collocation_issue",
      "portuguese_confusion": "what Portuguese speakers think it means",
      "actual_english_meaning": "correct English meaning/usage",
      "common_mistake": "typical error Brazilians make",
      "correct_usage": "proper way to use it",
      "teaching_strategy": "how to prevent this mistake",
      "examples": {{
        "wrong": "example of wrong usage",
        "correct": "example of correct usage"
      }},
      "severity": "high|medium|low"
    }}
  ],
  "overall_interference_level": "assessment of overall vocabulary interference risk",
  "teaching_priority": ["word1", "word2", "word3"],
  "prevention_focus": "main area to focus prevention efforts"
}}

Focus only on words that actually have interference potential."""

        try:
            # Usar structured output para garantir formato correto
            vocab_schema = self._create_vocabulary_interference_schema()
            structured_llm = self.llm.with_structured_output(vocab_schema)
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            logger.info("ü§ñ Consultando IA para an√°lise vocabul√°rio L1 com structured output...")
            analysis = await structured_llm.ainvoke(messages)
            
            # Validar que retornou dict
            if not isinstance(analysis, dict):
                logger.warning("‚ö†Ô∏è Structured output n√£o retornou dict, convertendo...")
                analysis = dict(analysis) if hasattr(analysis, '__dict__') else {}
            
            # Garantir campos obrigat√≥rios
            analysis = self._ensure_vocabulary_analysis_fields(analysis, vocabulary_items)
            
            logger.info(f"‚úÖ An√°lise vocabul√°rio L1 via structured output: {len(analysis.get('vocabulary_interference_items', []))} itens")
            return analysis
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise vocabul√°rio L1 com structured output: {str(e)}")
            return {
                "vocabulary_interference_items": [],
                "overall_interference_level": "medium",
                "teaching_priority": [item.word for item in vocabulary_items[:3]],
                "prevention_focus": "general_awareness"
            }
    
    async def _analyze_pronunciation_interference_ai(
        self,
        vocabulary_items: List[VocabularyItem],
        cefr_level: str,
        language_variant: str
    ) -> Dict[str, Any]:
        """An√°lise de interfer√™ncia de pron√∫ncia via IA."""
        
        pronunciation_data = []
        for item in vocabulary_items:
            pronunciation_info = f"Word: {item.word}"
            if item.phoneme:
                pronunciation_info += f" | IPA: {item.phoneme}"
            if item.syllable_count:
                pronunciation_info += f" | Syllables: {item.syllable_count}"
            pronunciation_data.append(pronunciation_info)
        
        system_prompt = """You are an expert phonetician specializing in pronunciation interference from Brazilian Portuguese to English.

Analyze pronunciation challenges that Brazilian Portuguese speakers will face with this vocabulary, considering:
- Portuguese phonological system vs English
- Common pronunciation errors of Brazilians
- Specific sounds that don't exist in Portuguese
- Stress pattern differences
- Syllable structure differences
- Connected speech challenges"""

        human_prompt = f"""Analyze pronunciation interference for Brazilian Portuguese speakers:

VOCABULARY PRONUNCIATION DATA:
{chr(10).join(pronunciation_data)}

STUDENT LEVEL: {cefr_level}
ENGLISH VARIANT: {language_variant}

Identify specific pronunciation challenges Brazilians will face with these words:

1. Individual sound challenges (sounds not in Portuguese)
2. Stress pattern difficulties
3. Syllable structure issues
4. Connected speech problems
5. Typical Brazilian pronunciation errors for each challenging word

Return detailed analysis in JSON:
{{
  "pronunciation_challenges": [
    {{
      "word": "vocabulary word",
      "ipa": "IPA transcription",
      "challenge_type": "sound_substitution|stress_pattern|syllable_structure|connected_speech",
      "specific_difficulty": "exact pronunciation challenge for Brazilians",
      "typical_brazilian_error": "how Brazilians typically mispronounce it",
      "correct_pronunciation": "correct way to pronounce",
      "teaching_technique": "specific technique to teach correct pronunciation",
      "practice_exercises": ["drill 1", "drill 2"],
      "difficulty_level": "easy|moderate|hard|very_hard"
    }}
  ],
  "overall_pronunciation_assessment": {{
    "difficulty_level": "assessment for {cefr_level} Brazilian learners",
    "main_challenge_areas": ["area1", "area2"],
    "teaching_priorities": ["priority1", "priority2"]
  }},
  "systematic_issues": [
    {{
      "pattern": "systematic pronunciation pattern issue",
      "explanation": "why this is hard for Brazilians",
      "solution": "teaching approach"
    }}
  ]
}}

Focus on realistic, specific challenges Brazilian speakers face."""

        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            content = response.content
            
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].strip()
            
            analysis = json.loads(content)
            
            logger.info(f"‚úÖ An√°lise pron√∫ncia L1 via IA: {len(analysis.get('pronunciation_challenges', []))} desafios")
            return analysis
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro na an√°lise de pron√∫ncia L1 via IA: {str(e)}")
            return {
                "pronunciation_challenges": [],
                "overall_pronunciation_assessment": {
                    "difficulty_level": "moderate",
                    "main_challenge_areas": ["consonant_clusters", "vowel_sounds"],
                    "teaching_priorities": ["clear_articulation", "stress_awareness"]
                },
                "systematic_issues": []
            }
    
    async def _generate_preventive_exercises_ai(
        self,
        main_analysis: Dict[str, Any],
        vocabulary_analysis: Dict[str, Any],
        pronunciation_analysis: Dict[str, Any],
        cefr_level: str
    ) -> List[Dict[str, Any]]:
        """Gerar exerc√≠cios preventivos via IA."""
        
        system_prompt = """You are an expert EFL curriculum designer specializing in L1 interference prevention exercises for Brazilian learners.

Create specific, practical exercises that prevent L1 interference based on the analysis provided. Exercises should be:
- Appropriate for the CEFR level
- Focused on the specific interference patterns identified
- Engaging and effective
- Easy for teachers to implement"""

        # Compilar dados da an√°lise
        interference_summary = {
            "grammar_patterns": main_analysis.get("interference_patterns", []),
            "vocabulary_issues": vocabulary_analysis.get("vocabulary_interference_items", []),
            "pronunciation_challenges": pronunciation_analysis.get("pronunciation_challenges", [])
        }
        
        human_prompt = f"""Create preventive exercises for L1 interference based on this analysis:

INTERFERENCE ANALYSIS:
{json.dumps(interference_summary, indent=2)}

STUDENT LEVEL: {cefr_level}

Create 3-5 different exercise types that specifically target the interference patterns identified. Each exercise should:

1. Target a specific interference pattern
2. Be appropriate for {cefr_level} level
3. Include clear instructions
4. Have specific examples
5. Focus on prevention rather than just correction

Return exercises in JSON format:
{{
  "preventive_exercises": [
    {{
      "exercise_type": "contrastive_awareness|error_prevention|pronunciation_drill|usage_practice",
      "title": "Clear, engaging title",
      "target_interference": "specific L1 issue this addresses",
      "instructions": "clear instructions for students",
      "content": {{
        "items": [
          {{
            "prompt": "exercise item",
            "correct_answer": "correct response",
            "explanation": "why this is correct"
          }}
        ],
        "additional_notes": "any extra guidance"
      }},
      "teaching_tips": ["tip1 for teacher", "tip2 for teacher"],
      "estimated_time": "time in minutes",
      "skill_focus": ["grammar", "vocabulary", "pronunciation"],
      "difficulty": "appropriate for level"
    }}
  ],
  "implementation_sequence": "recommended order to use exercises",
  "assessment_criteria": "how to evaluate student progress"
}}

Make exercises specific to the actual interference patterns found, not generic."""

        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            content = response.content
            
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].strip()
            
            exercises_data = json.loads(content)
            
            logger.info(f"‚úÖ Exerc√≠cios preventivos gerados via IA: {len(exercises_data.get('preventive_exercises', []))}")
            return exercises_data.get('preventive_exercises', [])
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro na gera√ß√£o de exerc√≠cios preventivos via IA: {str(e)}")
            return self._create_fallback_exercises(cefr_level)
    
    async def _generate_teaching_recommendations_ai(
        self,
        grammar_point: str,
        main_analysis: Dict[str, Any],
        cefr_level: str,
        unit_context: str
    ) -> List[str]:
        """Gerar recomenda√ß√µes pedag√≥gicas via IA."""
        
        system_prompt = """You are an experienced EFL teacher trainer specializing in teaching Brazilian students.

Provide specific, actionable teaching recommendations for preventing L1 interference based on the analysis provided."""

        human_prompt = f"""Based on this L1 interference analysis, provide specific teaching recommendations:

GRAMMAR POINT: {grammar_point}
STUDENT LEVEL: {cefr_level}
CONTEXT: {unit_context}

INTERFERENCE ANALYSIS:
{json.dumps(main_analysis, indent=2)}

Provide 5-8 specific, actionable teaching recommendations that help prevent the L1 interference patterns identified. Each recommendation should:

1. Be specific to the actual interference patterns found
2. Be practical for classroom implementation
3. Be appropriate for {cefr_level} level Brazilian students
4. Include concrete teaching techniques

Format as JSON array:
{{
  "teaching_recommendations": [
    "Specific recommendation 1 with concrete technique",
    "Specific recommendation 2 with concrete technique",
    ...
  ]
}}

Focus on prevention strategies, not just error correction."""

        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            content = response.content
            
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].strip()
            
            recommendations_data = json.loads(content)
            
            logger.info(f"‚úÖ Recomenda√ß√µes pedag√≥gicas geradas via IA: {len(recommendations_data.get('teaching_recommendations', []))}")
            return recommendations_data.get('teaching_recommendations', [])
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro na gera√ß√£o de recomenda√ß√µes via IA: {str(e)}")
            return [
                f"Focus on contrastive explanation of {grammar_point} vs Portuguese equivalents",
                f"Use explicit error prevention techniques for {cefr_level} level",
                "Provide abundant practice with immediate corrective feedback",
                "Emphasize differences in structure between Portuguese and English"
            ]
    
    async def _assess_difficulty_level_ai(
        self,
        grammar_point: str,
        vocabulary_items: List[VocabularyItem],
        cefr_level: str
    ) -> Dict[str, Any]:
        """Avaliar n√≠vel de dificuldade da interfer√™ncia via IA."""
        
        vocabulary_words = [item.word for item in vocabulary_items]
        
        system_prompt = """You are an expert in Second Language Acquisition assessment, specializing in interference difficulty evaluation for Brazilian learners."""

        human_prompt = f"""Assess the L1 interference difficulty level for Brazilian Portuguese speakers:

CONTENT TO ASSESS:
- Grammar Point: {grammar_point}
- Vocabulary: {', '.join(vocabulary_words)}
- Student Level: {cefr_level}

Evaluate:
1. How difficult will L1 interference be for Brazilian students?
2. What makes it particularly challenging?
3. What factors make it easier or harder?
4. Realistic timeline for mastery

Return assessment in JSON:
{{
  "overall_difficulty": "very_easy|easy|moderate|hard|very_hard",
  "difficulty_factors": [
    "factor 1 that makes it hard/easy",
    "factor 2 that makes it hard/easy"
  ],
  "mastery_timeline": "realistic time estimate for {cefr_level} students",
  "success_indicators": [
    "sign 1 that students are overcoming interference",
    "sign 2 that students are overcoming interference"
  ],
  "difficulty_score": 0.75
}}

Be realistic about Brazilian learner challenges."""

        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            content = response.content
            
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].strip()
            
            assessment = json.loads(content)
            
            logger.info(f"‚úÖ Avalia√ß√£o de dificuldade via IA: {assessment.get('overall_difficulty', 'moderate')}")
            return assessment
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro na avalia√ß√£o de dificuldade via IA: {str(e)}")
            return {
                "overall_difficulty": "moderate",
                "difficulty_factors": ["Cross-linguistic differences", "Brazilian learner patterns"],
                "mastery_timeline": f"3-6 weeks for {cefr_level} students with focused practice",
                "success_indicators": ["Reduced L1 transfer errors", "Increased awareness of differences"],
                "difficulty_score": 0.6
            }
    
    # =============================================================================
    # FALLBACK METHODS
    # =============================================================================
    
    async def _fallback_main_analysis(
        self,
        grammar_point: str,
        vocabulary_words: List[str],
        cefr_level: str
    ) -> Dict[str, Any]:
        """An√°lise de fallback quando IA falha."""
        return {
            "interference_patterns": [
                {
                    "category": "general_interference",
                    "portuguese_pattern": f"Portuguese structure related to {grammar_point}",
                    "incorrect_english_transfer": "Literal translation from Portuguese",
                    "correct_english": f"Proper English {grammar_point} structure",
                    "explanation": f"Portuguese and English differ in {grammar_point} usage",
                    "prevention_technique": "Explicit contrastive instruction",
                    "example_context": f"Context-specific example with {vocabulary_words[0] if vocabulary_words else 'vocabulary'}",
                    "difficulty_level": f"Moderate for {cefr_level}",
                    "frequency": "Common among Brazilian learners"
                }
            ],
            "predicted_common_mistakes": [
                {
                    "mistake": f"Common Brazilian error with {grammar_point}",
                    "correction": f"Correct {grammar_point} usage",
                    "reason": "L1 transfer from Portuguese"
                }
            ],
            "contrastive_examples": [
                {
                    "portuguese": f"Portuguese equivalent of {grammar_point}",
                    "english_wrong": "Literal English translation",
                    "english_correct": f"Correct English {grammar_point}",
                    "teaching_point": "Emphasize structural difference"
                }
            ],
            "prevention_strategies": [
                "Use contrastive analysis techniques",
                "Provide explicit error prevention instruction"
            ],
            "confidence_score": 0.7
        }
    
    def _create_fallback_exercises(self, cefr_level: str) -> List[Dict[str, Any]]:
        """Exerc√≠cios de fallback quando IA falha."""
        return [
            {
                "exercise_type": "contrastive_awareness",
                "title": "Portuguese vs English Comparison",
                "target_interference": "General L1 transfer",
                "instructions": "Compare Portuguese and English structures",
                "content": {
                    "items": [
                        {
                            "prompt": "Identify the difference between Portuguese and English",
                            "correct_answer": "English structure differs from Portuguese",
                            "explanation": "Languages have different patterns"
                        }
                    ],
                    "additional_notes": "Focus on preventing direct translation"
                },
                "teaching_tips": ["Use explicit comparison", "Highlight differences"],
                "estimated_time": "10-15 minutes",
                "skill_focus": ["grammar", "awareness"],
                "difficulty": f"Appropriate for {cefr_level}"
            }
        ]
    
    # =============================================================================
    # CACHE MANAGEMENT
    # =============================================================================
    
    def _generate_cache_key(
        self,
        grammar_point: str,
        vocabulary_items: List[VocabularyItem],
        cefr_level: str,
        unit_context: str
    ) -> str:
        """Gerar chave √∫nica para cache."""
        vocab_words = [item.word for item in vocabulary_items]
        content = f"{grammar_point}_{cefr_level}_{unit_context}_{'-'.join(vocab_words[:5])}"
        return f"l1_analysis_{hash(content)}"
    
    def _get_from_cache(self, key: str) -> Optional[Dict[str, Any]]:
        """Recuperar an√°lise do cache."""
        if key in self._analysis_cache:
            cached_data = self._analysis_cache[key]
            # Verificar se n√£o expirou (2 horas)
            if time.time() - cached_data.get("cached_at", 0) < 7200:
                return cached_data.get("data")
        return None
    
    def _save_to_cache(self, key: str, data: Dict[str, Any]) -> None:
        """Salvar an√°lise no cache."""
        # Limpar cache se muito grande
        if len(self._analysis_cache) >= self._max_cache_size:
            oldest_key = min(
                self._analysis_cache.keys(),
                key=lambda k: self._analysis_cache[k].get("cached_at", 0)
            )
            del self._analysis_cache[oldest_key]
        
        self._analysis_cache[key] = {
            "data": data,
            "cached_at": time.time()
        }
    
    def clear_cache(self) -> None:
        """Limpar cache de an√°lises."""
        self._analysis_cache.clear()
        logger.info("üóëÔ∏è Cache de an√°lises L1 limpo")
    
    # =============================================================================
    # PUBLIC INTERFACE METHODS
    # =============================================================================
    
    async def quick_interference_check(
        self,
        word_or_phrase: str,
        cefr_level: str,
        context: str = ""
    ) -> Dict[str, Any]:
        """
        Verifica√ß√£o r√°pida de interfer√™ncia para uma palavra ou frase espec√≠fica.
        
        Args:
            word_or_phrase: Palavra ou frase para verificar
            cefr_level: N√≠vel CEFR do estudante
            context: Contexto opcional
            
        Returns:
            Dict com an√°lise r√°pida de interfer√™ncia
        """
        try:
            system_prompt = """You are an expert in L1 interference for Brazilian Portuguese speakers learning English.

Provide a quick, focused analysis of potential L1 interference for the given word or phrase."""

            human_prompt = f"""Quick L1 interference check for Brazilian learners:

WORD/PHRASE: "{word_or_phrase}"
STUDENT LEVEL: {cefr_level}
CONTEXT: {context if context else "General usage"}

Analyze:
1. Is there potential L1 interference from Portuguese?
2. What specific interference might occur?
3. Quick prevention tip

Return brief analysis in JSON:
{{
  "has_interference": true/false,
  "interference_type": "false_friend|structure|pronunciation|usage|none",
  "quick_explanation": "brief explanation of the issue",
  "prevention_tip": "one quick teaching tip",
  "severity": "low|medium|high"
}}

Be concise but accurate."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            content = response.content
            
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].strip()
            
            result = json.loads(content)
            
            logger.info(f"‚úÖ Verifica√ß√£o r√°pida L1 para '{word_or_phrase}': {result.get('interference_type', 'none')}")
            return result
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro na verifica√ß√£o r√°pida L1: {str(e)}")
            return {
                "has_interference": False,
                "interference_type": "unknown",
                "quick_explanation": "Unable to analyze at this time",
                "prevention_tip": "Monitor for common Brazilian learner errors",
                "severity": "medium"
            }
    
    async def generate_contrastive_explanation(
        self,
        english_structure: str,
        portuguese_equivalent: str,
        cefr_level: str
    ) -> str:
        """
        Gerar explica√ß√£o contrastiva entre estrutura inglesa e portuguesa.
        
        Args:
            english_structure: Estrutura em ingl√™s
            portuguese_equivalent: Equivalente em portugu√™s
            cefr_level: N√≠vel CEFR
            
        Returns:
            Explica√ß√£o contrastiva detalhada
        """
        try:
            system_prompt = f"""You are an expert EFL teacher specializing in contrastive analysis for Brazilian students at {cefr_level} level.

Create a clear, pedagogical explanation comparing English and Portuguese structures."""

            human_prompt = f"""Create a contrastive explanation for {cefr_level} Brazilian students:

ENGLISH STRUCTURE: {english_structure}
PORTUGUESE EQUIVALENT: {portuguese_equivalent}
STUDENT LEVEL: {cefr_level}

Explain:
1. How the structures differ
2. Why Brazilians might make mistakes
3. Key teaching points to emphasize
4. Simple rule to remember

Make the explanation appropriate for {cefr_level} students - clear and not too complex."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            explanation = response.content
            
            logger.info(f"‚úÖ Explica√ß√£o contrastiva gerada para {cefr_level}")
            return explanation
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro na gera√ß√£o de explica√ß√£o contrastiva: {str(e)}")
            return f"Compare {english_structure} in English with {portuguese_equivalent} in Portuguese. Notice the structural differences and practice the English pattern."
    
    async def predict_common_errors(
        self,
        lesson_content: Dict[str, Any],
        cefr_level: str
    ) -> List[Dict[str, Any]]:
        """
        Prever erros comuns que estudantes brasileiros far√£o com o conte√∫do.
        
        Args:
            lesson_content: Conte√∫do da li√ß√£o (grammar_point, vocabulary, etc.)
            cefr_level: N√≠vel CEFR
            
        Returns:
            Lista de erros preditos com corre√ß√µes
        """
        try:
            system_prompt = """You are an experienced EFL teacher who has taught thousands of Brazilian students.

Predict the most likely errors Brazilian students will make with this lesson content."""

            human_prompt = f"""Predict common errors Brazilian students will make:

LESSON CONTENT:
{json.dumps(lesson_content, indent=2)}

STUDENT LEVEL: {cefr_level}

Based on your experience with Brazilian learners, predict:
1. The 5 most likely errors they will make
2. Why they will make each error
3. How to correct each error

Return predictions in JSON:
{{
  "predicted_errors": [
    {{
      "error_category": "grammar|vocabulary|pronunciation|usage",
      "student_will_say": "what student will incorrectly say/write",
      "correct_form": "the correct form",
      "why_this_error": "reason based on Portuguese interference",
      "correction_strategy": "how to help them fix it",
      "likelihood": "very_high|high|medium|low"
    }}
  ]
}}

Focus on realistic, specific errors based on Portuguese L1 patterns."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            content = response.content
            
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].strip()
            
            predictions = json.loads(content)
            
            logger.info(f"‚úÖ Predi√ß√µes de erro geradas: {len(predictions.get('predicted_errors', []))}")
            return predictions.get('predicted_errors', [])
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro na predi√ß√£o de erros comuns: {str(e)}")
            return [
                {
                    "error_category": "general",
                    "student_will_say": "Common Brazilian learner error",
                    "correct_form": "Correct English form",
                    "why_this_error": "L1 Portuguese interference",
                    "correction_strategy": "Explicit instruction and practice",
                    "likelihood": "medium"
                }
            ]
    
    async def create_awareness_exercise(
        self,
        interference_pattern: Dict[str, Any],
        cefr_level: str
    ) -> Dict[str, Any]:
        """
        Criar exerc√≠cio de conscientiza√ß√£o para padr√£o espec√≠fico de interfer√™ncia.
        
        Args:
            interference_pattern: Padr√£o de interfer√™ncia identificado
            cefr_level: N√≠vel CEFR
            
        Returns:
            Exerc√≠cio estruturado de conscientiza√ß√£o
        """
        try:
            system_prompt = f"""You are an expert exercise designer for Brazilian EFL learners at {cefr_level} level.

Create a focused awareness exercise for the specific interference pattern provided."""

            human_prompt = f"""Create an awareness exercise for this L1 interference pattern:

INTERFERENCE PATTERN:
{json.dumps(interference_pattern, indent=2)}

STUDENT LEVEL: {cefr_level}

Design an exercise that:
1. Helps students become aware of this interference
2. Is appropriate for {cefr_level} level
3. Is engaging and effective
4. Takes 5-10 minutes to complete

Return exercise in JSON:
{{
  "exercise_title": "clear, engaging title",
  "objective": "what students will learn",
  "instructions": "clear step-by-step instructions",
  "content": {{
    "awareness_items": [
      {{
        "portuguese_version": "Portuguese structure/phrase",
        "english_wrong": "incorrect English (L1 transfer)",
        "english_correct": "correct English form",
        "explanation": "brief explanation of difference"
      }}
    ],
    "practice_items": [
      {{
        "situation": "context for practice",
        "student_task": "what student should do",
        "correct_answer": "expected correct response"
      }}
    ]
  }},
  "teacher_notes": ["tip 1", "tip 2"],
  "extension_activity": "optional follow-up activity"
}}

Make it specific to the interference pattern provided."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            content = response.content
            
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].strip()
            
            exercise = json.loads(content)
            
            logger.info(f"‚úÖ Exerc√≠cio de conscientiza√ß√£o criado: {exercise.get('exercise_title', 'Exercise')}")
            return exercise
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro na cria√ß√£o de exerc√≠cio de conscientiza√ß√£o: {str(e)}")
            return {
                "exercise_title": "L1 Interference Awareness",
                "objective": "Recognize differences between Portuguese and English",
                "instructions": "Compare the Portuguese and English versions",
                "content": {
                    "awareness_items": [],
                    "practice_items": []
                },
                "teacher_notes": ["Focus on contrastive explanation"],
                "extension_activity": "Additional practice with similar patterns"
            }
    
    def get_analysis_statistics(self) -> Dict[str, Any]:
        """Obter estat√≠sticas das an√°lises realizadas."""
        return {
            "cache_size": len(self._analysis_cache),
            "max_cache_size": self._max_cache_size,
            "cache_hit_ratio": "Not tracked in current implementation",
            "total_analyses": "Not tracked in current implementation",
            "ai_model": self.openai_config.get("model", "gpt-4o-mini"),
            "service_status": "active"
        }


# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

async def analyze_text_for_l1_interference(
    text: str,
    cefr_level: str,
    analyzer: Optional[L1InterferenceAnalyzer] = None
) -> Dict[str, Any]:
    """
    Fun√ß√£o utilit√°ria para analisar um texto livre para interfer√™ncias L1.
    
    Args:
        text: Texto para analisar
        cefr_level: N√≠vel CEFR do estudante
        analyzer: Inst√¢ncia do analisador (opcional)
        
    Returns:
        An√°lise de interfer√™ncias no texto
    """
    if analyzer is None:
        analyzer = L1InterferenceAnalyzer()
    
    try:
        system_prompt = """You are an expert in analyzing L1 interference in student writing/speaking for Brazilian Portuguese speakers learning English."""

        human_prompt = f"""Analyze this text for L1 interference from Brazilian Portuguese:

TEXT TO ANALYZE: "{text}"
STUDENT LEVEL: {cefr_level}

Identify:
1. Actual L1 interference errors present
2. Likely causes (Portuguese influence)
3. Corrections needed
4. Teaching priorities

Return analysis in JSON:
{{
  "interference_errors_found": [
    {{
      "error_text": "specific error in the text",
      "error_type": "grammar|vocabulary|word_order|preposition|article",
      "correct_form": "how it should be written",
      "portuguese_influence": "why Brazilian made this error",
      "teaching_point": "what to focus on"
    }}
  ],
  "overall_assessment": "general assessment of L1 interference level",
  "teaching_priorities": ["priority 1", "priority 2"],
  "positive_aspects": ["what student did correctly"]
}}"""

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ]
        
        response = await analyzer.llm.ainvoke(messages)
        content = response.content
        
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].strip()
        
        analysis = json.loads(content)
        return analysis
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erro na an√°lise de texto para L1: {str(e)}")
        return {
            "interference_errors_found": [],
            "overall_assessment": "Unable to analyze at this time",
            "teaching_priorities": ["General error correction"],
            "positive_aspects": ["Student attempted communication"]
        }


def create_l1_interference_report(
    analysis_data: Dict[str, Any],
    unit_title: str,
    cefr_level: str
) -> str:
    """
    Criar relat√≥rio resumido de interfer√™ncia L1.
    
    Args:
        analysis_data: Dados da an√°lise de interfer√™ncia
        unit_title: T√≠tulo da unidade
        cefr_level: N√≠vel CEFR
        
    Returns:
        Relat√≥rio formatado em texto
    """
    try:
        report_lines = [
            f"L1 INTERFERENCE ANALYSIS REPORT",
            f"Unit: {unit_title}",
            f"Level: {cefr_level}",
            f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            "",
            "MAIN INTERFERENCE PATTERNS:"
        ]
        
        patterns = analysis_data.get("main_interference_patterns", {}).get("interference_patterns", [])
        for i, pattern in enumerate(patterns[:5], 1):
            report_lines.extend([
                f"{i}. {pattern.get('category', 'Unknown').title()}",
                f"   Portuguese: {pattern.get('portuguese_pattern', 'N/A')}",
                f"   Common Error: {pattern.get('incorrect_english_transfer', 'N/A')}",
                f"   Correct Form: {pattern.get('correct_english', 'N/A')}",
                f"   Prevention: {pattern.get('prevention_technique', 'N/A')}",
                ""
            ])
        
        # Vocabul√°rio
        vocab_issues = analysis_data.get("vocabulary_interference", {}).get("vocabulary_interference_items", [])
        if vocab_issues:
            report_lines.extend([
                "VOCABULARY INTERFERENCE:",
                ""
            ])
            for item in vocab_issues[:3]:
                report_lines.extend([
                    f"‚Ä¢ {item.get('word', 'Unknown')} - {item.get('interference_type', 'Unknown')}",
                    f"  Issue: {item.get('common_mistake', 'N/A')}",
                    f"  Correct: {item.get('correct_usage', 'N/A')}",
                    ""
                ])
        
        # Recomenda√ß√µes
        recommendations = analysis_data.get("teaching_recommendations", [])
        if recommendations:
            report_lines.extend([
                "TEACHING RECOMMENDATIONS:",
                ""
            ])
            for i, rec in enumerate(recommendations[:5], 1):
                report_lines.append(f"{i}. {rec}")
            report_lines.append("")
        
        # Dificuldade
        difficulty = analysis_data.get("difficulty_assessment", {})
        if difficulty:
            report_lines.extend([
                "DIFFICULTY ASSESSMENT:",
                f"Overall Level: {difficulty.get('overall_difficulty', 'Unknown').title()}",
                f"Mastery Timeline: {difficulty.get('mastery_timeline', 'Unknown')}",
                f"Confidence Score: {analysis_data.get('ai_confidence_score', 'N/A')}",
                ""
            ])
        
        return "\n".join(report_lines)
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erro na cria√ß√£o do relat√≥rio L1: {str(e)}")
        return f"L1 Interference Analysis Report for {unit_title} ({cefr_level}) - Report generation error"


# Inst√¢ncia global do servi√ßo
l1_interference_analyzer = L1InterferenceAnalyzer()