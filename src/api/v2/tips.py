# src/api/v2/tips.py
"""
Endpoints para gera√ß√£o de estrat√©gias TIPS para unidades lexicais.
Implementa√ß√£o das 6 estrat√©gias TIPS do IVO V2 Guide com sele√ß√£o inteligente RAG.
"""

from fastapi import APIRouter, HTTPException, Depends, Request
from typing import List, Optional, Dict, Any
import logging
import time

from src.services.hierarchical_database import hierarchical_db
from src.services.tips_generator import TipsGeneratorService
from src.core.unit_models import (
    SuccessResponse, ErrorResponse, TipsContent, TipsGenerationRequest
)
from src.core.enums import (
    CEFRLevel, LanguageVariant, UnitType, TipStrategy, UnitStatus
)
from src.core.audit_logger import (
    audit_logger_instance, AuditEventType, audit_endpoint, extract_unit_info
)
from src.core.rate_limiter import rate_limit_dependency
from src.core.webhook_utils import validate_webhook_url, extract_webhook_metadata, WebhookResponse
from src.services.webhook_service import webhook_service

router = APIRouter()
logger = logging.getLogger(__name__)


async def rate_limit_tips_generation(request: Request):
    """Rate limiting espec√≠fico para gera√ß√£o de TIPS."""
    await rate_limit_dependency(request, "generate_content")


async def _generate_tips_for_unit_sync(
    unit_id: str,
    tips_request: TipsGenerationRequest,
    request: Request,
    _: None = None
):
    """
    Gerar estrat√©gias TIPS para unidade lexical com sele√ß√£o inteligente.
    
    Flow do IVO V2:
    1. Buscar unidade e validar que √© lexical_unit
    2. Verificar se possui vocabul√°rio e sentences
    3. Usar RAG para sele√ß√£o da estrat√©gia TIPS adequada
    4. Aplicar uma das 6 estrat√©gias TIPS baseada no vocabul√°rio
    5. Gerar conte√∫do espec√≠fico da estrat√©gia
    6. Salvar e atualizar status da unidade
    """
    try:
        logger.info(f"Iniciando gera√ß√£o de TIPS para unidade: {unit_id}")
        
        # 1. Buscar e validar unidade
        unit = await hierarchical_db.get_unit(unit_id)
        if not unit:
            raise HTTPException(
                status_code=404,
                detail=f"Unidade {unit_id} n√£o encontrada"
            )
        
        # 2. Verificar se √© unidade lexical
        if unit.unit_type.value != "lexical_unit":
            raise HTTPException(
                status_code=400,
                detail=f"TIPS s√£o apenas para unidades lexicais. Esta unidade √© {unit.unit_type.value}. Use /grammar para unidades gramaticais."
            )
        
        # 3. Verificar status adequado
        if unit.status.value not in ["content_pending"]:
            if unit.status.value in ["creating", "vocab_pending"]:
                raise HTTPException(
                    status_code=400,
                    detail="Unidade deve ter vocabul√°rio e sentences antes de gerar TIPS."
                )
            elif unit.tips:
                logger.info(f"Unidade {unit_id} j√° possui TIPS - regenerando")
        
        # 4. Verificar pr√©-requisitos
        if not unit.vocabulary or not unit.vocabulary.get("items"):
            raise HTTPException(
                status_code=400,
                detail="Unidade deve ter vocabul√°rio antes de gerar TIPS."
            )
        
        if not unit.sentences or not unit.sentences.get("sentences"):
            raise HTTPException(
                status_code=400,
                detail="Unidade deve ter sentences antes de gerar TIPS."
            )
        
        # 5. Buscar contexto da hierarquia
        course = await hierarchical_db.get_course(unit.course_id)
        book = await hierarchical_db.get_book(unit.book_id)
        
        if not course or not book:
            raise HTTPException(
                status_code=400,
                detail="Hierarquia inv√°lida: curso ou book n√£o encontrado"
            )
        
        # 6. Buscar contexto RAG para sele√ß√£o da estrat√©gia
        logger.info("Coletando contexto RAG para sele√ß√£o inteligente de estrat√©gia TIPS...")
        
        used_strategies = await hierarchical_db.get_used_strategies(
            unit.course_id, unit.book_id, unit.sequence_order
        )
        
        taught_vocabulary = await hierarchical_db.get_taught_vocabulary(
            unit.course_id, unit.book_id, unit.sequence_order
        )
        
        # 7. Preparar dados para sele√ß√£o e gera√ß√£o
        unit_data = {
            "title": unit.title,
            "context": unit.context,
            "cefr_level": unit.cefr_level.value,
            "language_variant": unit.language_variant.value,
            "unit_type": unit.unit_type.value,
            "main_aim": unit.main_aim,
            "subsidiary_aims": unit.subsidiary_aims
        }
        
        content_data = {
            "vocabulary": unit.vocabulary,
            "sentences": unit.sentences
        }
        
        hierarchy_context = {
            "course_name": course.name,
            "book_name": book.name,
            "sequence_order": unit.sequence_order,
            "target_level": book.target_level.value
        }
        
        rag_context = {
            "used_strategies": used_strategies,
            "taught_vocabulary": taught_vocabulary,
            "progression_level": _determine_progression_level(unit.sequence_order),
            "strategy_density": len(used_strategies) / max(unit.sequence_order, 1)
        }
        
        # 8. Gerar TIPS usando service
        start_time = time.time()
        tips_generator = TipsGeneratorService()
        
        tips_content = await tips_generator.generate_tips_for_unit(
            tips_request,
            unit_data,
            content_data,
            hierarchy_context,
            rag_context
        )
        
        generation_time = time.time() - start_time
        
        # 9. Salvar TIPS na unidade
        tips_for_db = tips_content.model_dump()
        await hierarchical_db.update_unit_content(
            unit_id, 
            "tips", 
            tips_for_db
        )
        
        # 10. Fazer upsert de embedding dos tips gerados
        logger.info("üìä Criando embedding dos tips...")
        try:
            embedding_success = await hierarchical_db.upsert_single_content_embedding(
                unit_id=unit_id,
                content_type="tips",
                content_data=tips_for_db
            )
            if embedding_success:
                logger.info("‚úÖ Embedding dos tips criado com sucesso")
            else:
                logger.warning("‚ö†Ô∏è Falha ao criar embedding dos tips (n√£o afeta resultado)")
        except Exception as embedding_error:
            logger.warning(f"‚ö†Ô∏è Erro ao criar embedding dos tips: {str(embedding_error)}")
        
        # 11. Atualizar lista de estrat√©gias usadas
        strategy_name = tips_content.strategy.value
        current_strategies = unit.strategies_used or []
        updated_strategies = current_strategies + [strategy_name]
        
        await hierarchical_db.update_unit_content(
            unit_id,
            "strategies_used",
            updated_strategies
        )
        
        # 11. Atualizar status da unidade
        await hierarchical_db.update_unit_status(unit_id, UnitStatus.ASSESSMENTS_PENDING)
        
        # 12. Log de auditoria - CORRIGIDO: tips_content ao inv√©s de tips_data
        await audit_logger_instance.log_content_generation(
            request=request,
            generation_type="tips",
            unit_id=unit_id,
            book_id=unit.book_id,
            course_id=unit.course_id,
            content_stats={
                "strategy_selected": strategy_name,
                "vocabulary_coverage": len(tips_content.vocabulary_coverage),
                "examples_count": len(tips_content.examples),
                "practice_suggestions": len(tips_content.practice_suggestions),
                "memory_techniques": len(tips_content.memory_techniques),
                "selection_rationale": tips_content.selection_rationale,
                "complementary_strategies": tips_content.complementary_strategies,
                "strategy_diversity_score": len(set(used_strategies)) / 6 if used_strategies else 0
            },
            ai_usage={
                "model": "gpt-4o-mini",
                "generation_time": generation_time,
                "strategy_selection_algorithm": "rag_based_intelligent_selection"
            },
            processing_time=generation_time,
            success=True
        )
        
        return SuccessResponse(
            data={
                "tips": tips_content.dict(),
                "generation_stats": {
                    "strategy_selected": strategy_name,
                    "vocabulary_coverage": len(tips_content.vocabulary_coverage),
                    "total_examples": len(tips_content.examples),
                    "practice_suggestions": len(tips_content.practice_suggestions),
                    "processing_time": f"{generation_time:.2f}s"
                },
                "unit_progression": {
                    "unit_id": unit_id,
                    "previous_status": unit.status.value,
                    "new_status": "assessments_pending",
                    "next_step": "Gerar assessments para finalizar a unidade"
                },
                "strategy_analysis": {
                    "selected_strategy": strategy_name,
                    "selection_rationale": tips_content.selection_rationale,
                    "used_strategies_context": used_strategies,
                    "complementary_strategies": tips_content.complementary_strategies,
                    "phonetic_focus": tips_content.phonetic_focus
                }
            },
            message=f"Estrat√©gia TIPS '{strategy_name}' gerada com sucesso para unidade '{unit.title}'",
            hierarchy_info={
                "course_id": unit.course_id,
                "book_id": unit.book_id,
                "unit_id": unit_id,
                "sequence": unit.sequence_order
            },
            next_suggested_actions=[
                "Gerar assessments para finalizar",
                f"POST /api/v2/units/{unit_id}/assessments",
                "Verificar estrat√©gia aplicada",
                f"GET /api/v2/units/{unit_id}/tips",
                "Analisar qualidade da estrat√©gia",
                f"GET /api/v2/units/{unit_id}/tips/analysis"
            ]
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro ao gerar TIPS para unidade {unit_id}: {str(e)}")
        
        # Log de erro
        await audit_logger_instance.log_content_generation(
            request=request,
            generation_type="tips",
            unit_id=unit_id,
            book_id=getattr(unit, 'book_id', ''),
            course_id=getattr(unit, 'course_id', ''),
            success=False,
            error_details=str(e)
        )
        
        raise HTTPException(
            status_code=500,
            detail=f"Erro interno na gera√ß√£o de TIPS: {str(e)}"
        )


# CORRIGIDO: Removidas fun√ß√µes duplicadas _analyze_tips_content_quality, 
# _analyze_vocabulary_integration, _analyze_pedagogical_effectiveness,
# _analyze_phonetic_components, _analyze_contextual_relevance,
# _generate_tips_recommendations, _calculate_tips_quality, 
# _get_effectiveness_recommendations que estavam definidas duas vezes


@router.post("/units/{unit_id}/tips")
@audit_endpoint(AuditEventType.UNIT_CONTENT_GENERATED, extract_unit_info)
async def generate_tips_for_unit(
    unit_id: str,
    tips_request: TipsGenerationRequest,
    request: Request,
    _: None = Depends(rate_limit_tips_generation)
):
    """Gerar estrat√©gias TIPS para unidade com suporte a webhooks."""
    try:
        # Verificar se deve processar ass√≠ncronamente
        if hasattr(tips_request, 'webhook_url') and tips_request.webhook_url:
            # Validar webhook_url
            is_valid, error = validate_webhook_url(tips_request.webhook_url)
            if not is_valid:
                raise HTTPException(status_code=400, detail=f"webhook_url inv√°lida: {error}")
            
            # Executar ass√≠ncronamente
            task_id = webhook_service.generate_task_id("tips")
            metadata = extract_webhook_metadata("tips", unit_id, tips_request.model_dump(), {"endpoint": "tips"})
            clean_request = tips_request.model_copy()
            clean_request.webhook_url = None
            
            await webhook_service.execute_async_task(
                task_id=task_id,
                webhook_url=tips_request.webhook_url,
                task_func=_generate_tips_for_unit_sync,
                task_args=(unit_id, clean_request, request),
                task_kwargs={},
                metadata=metadata
            )
            
            return WebhookResponse.async_accepted(task_id, tips_request.webhook_url, "tips")
        
        else:
            # Processamento s√≠ncrono
            return await _generate_tips_for_unit_sync(unit_id, tips_request, request)
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro no endpoint de tips {unit_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")


@router.get("/units/{unit_id}/tips", response_model=SuccessResponse)
async def get_unit_tips(unit_id: str, request: Request):
    """Obter estrat√©gias TIPS da unidade."""
    try:
        logger.info(f"Buscando TIPS da unidade: {unit_id}")
        
        # Buscar unidade
        unit = await hierarchical_db.get_unit(unit_id)
        if not unit:
            raise HTTPException(
                status_code=404,
                detail=f"Unidade {unit_id} n√£o encontrada"
            )
        
        # Verificar se √© unidade lexical
        if unit.unit_type.value != "lexical_unit":
            raise HTTPException(
                status_code=400,
                detail=f"Esta unidade √© {unit.unit_type.value}. TIPS s√£o apenas para unidades lexicais."
            )
        
        # Verificar se possui TIPS
        if not unit.tips:
            return SuccessResponse(
                data={
                    "has_tips": False,
                    "unit_status": unit.status.value,
                    "unit_type": unit.unit_type.value,
                    "message": "Unidade ainda n√£o possui estrat√©gias TIPS geradas",
                    "prerequisites": {
                        "has_vocabulary": bool(unit.vocabulary),
                        "has_sentences": bool(unit.sentences),
                        "is_lexical_unit": unit.unit_type.value == "lexical_unit"
                    }
                },
                message="TIPS n√£o encontradas",
                hierarchy_info={
                    "course_id": unit.course_id,
                    "book_id": unit.book_id,
                    "unit_id": unit_id,
                    "sequence": unit.sequence_order
                },
                next_suggested_actions=[
                    "Gerar estrat√©gias TIPS",
                    f"POST /api/v2/units/{unit_id}/tips"
                ]
            )
        
        # Buscar contexto adicional
        course = await hierarchical_db.get_course(unit.course_id)
        book = await hierarchical_db.get_book(unit.book_id)
        
        # An√°lise das TIPS
        tips_data = unit.tips
        
        return SuccessResponse(
            data={
                "tips": tips_data,
                "analysis": {
                    "strategy_used": tips_data.get("strategy", "unknown"),
                    "vocabulary_coverage": len(tips_data.get("vocabulary_coverage", [])),
                    "examples_count": len(tips_data.get("examples", [])),
                    "practice_suggestions_count": len(tips_data.get("practice_suggestions", [])),
                    "memory_techniques_count": len(tips_data.get("memory_techniques", [])),
                    "phonetic_focus": tips_data.get("phonetic_focus", []),
                    "pronunciation_tips": tips_data.get("pronunciation_tips", [])
                },
                "unit_context": {
                    "unit_title": unit.title,
                    "unit_type": unit.unit_type.value,
                    "cefr_level": unit.cefr_level.value,
                    "unit_status": unit.status.value,
                    "course_name": course.name if course else None,
                    "book_name": book.name if book else None,
                    "sequence_order": unit.sequence_order
                },
                "strategy_context": {
                    "selection_rationale": tips_data.get("selection_rationale", ""),
                    "complementary_strategies": tips_data.get("complementary_strategies", []),
                    "vocabulary_integration": tips_data.get("vocabulary_coverage", [])
                },
                "has_tips": True
            },
            message=f"Estrat√©gias TIPS da unidade '{unit.title}'",
            hierarchy_info={
                "course_id": unit.course_id,
                "book_id": unit.book_id,
                "unit_id": unit_id,
                "sequence": unit.sequence_order
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro ao buscar TIPS da unidade {unit_id}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro interno: {str(e)}"
        )


@router.put("/units/{unit_id}/tips", response_model=SuccessResponse)
async def update_unit_tips(
    unit_id: str,
    tips_data: Dict[str, Any],
    request: Request,
    _: None = Depends(rate_limit_tips_generation)
):
    """Atualizar estrat√©gias TIPS da unidade (edi√ß√£o manual)."""
    try:
        logger.info(f"Atualizando TIPS da unidade: {unit_id}")
        
        # Verificar se unidade existe
        unit = await hierarchical_db.get_unit(unit_id)
        if not unit:
            raise HTTPException(
                status_code=404,
                detail=f"Unidade {unit_id} n√£o encontrada"
            )
        
        # Verificar se √© unidade lexical
        if unit.unit_type.value != "lexical_unit":
            raise HTTPException(
                status_code=400,
                detail="TIPS s√£o apenas para unidades lexicais"
            )
        
        # Validar estrutura b√°sica dos dados
        if not isinstance(tips_data, dict):
            raise HTTPException(
                status_code=400,
                detail="Dados de TIPS devem ser um objeto JSON"
            )
        
        required_fields = ["strategy", "title", "explanation", "examples"]
        for field in required_fields:
            if field not in tips_data:
                raise HTTPException(
                    status_code=400,
                    detail=f"Campo obrigat√≥rio ausente: {field}"
                )
        
        # Validar estrat√©gia
        valid_strategies = [strategy.value for strategy in TipStrategy]
        if tips_data["strategy"] not in valid_strategies:
            raise HTTPException(
                status_code=400,
                detail=f"Estrat√©gia inv√°lida. Deve ser uma de: {valid_strategies}"
            )
        
        # Atualizar timestamps
        tips_data["updated_at"] = time.time()
        
        # Salvar no banco
        await hierarchical_db.update_unit_content(unit_id, "tips", tips_data)
        
        # Atualizar estrat√©gias usadas
        strategy_name = tips_data["strategy"]
        current_strategies = unit.strategies_used or []
        if strategy_name not in current_strategies:
            updated_strategies = current_strategies + [strategy_name]
            await hierarchical_db.update_unit_content(unit_id, "strategies_used", updated_strategies)
        
        # Log da atualiza√ß√£o
        await audit_logger_instance.log_event(
            event_type=AuditEventType.UNIT_UPDATED,
            request=request,
            additional_data={
                "update_type": "tips_manual_edit",
                "strategy": strategy_name,
                "unit_id": unit_id
            }
        )
        
        return SuccessResponse(
            data={
                "updated": True,
                "tips": tips_data,
                "update_stats": {
                    "strategy": strategy_name,
                    "examples_count": len(tips_data.get("examples", [])),
                    "update_timestamp": tips_data["updated_at"]
                }
            },
            message=f"Estrat√©gias TIPS atualizadas com sucesso",
            hierarchy_info={
                "course_id": unit.course_id,
                "book_id": unit.book_id,
                "unit_id": unit_id,
                "sequence": unit.sequence_order
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro ao atualizar TIPS da unidade {unit_id}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro interno: {str(e)}"
        )


@router.delete("/units/{unit_id}/tips", response_model=SuccessResponse)
async def delete_unit_tips(unit_id: str, request: Request):
    """Deletar estrat√©gias TIPS da unidade."""
    try:
        logger.warning(f"Deletando TIPS da unidade: {unit_id}")
        
        # Verificar se unidade existe
        unit = await hierarchical_db.get_unit(unit_id)
        if not unit:
            raise HTTPException(
                status_code=404,
                detail=f"Unidade {unit_id} n√£o encontrada"
            )
        
        # Verificar se possui TIPS
        if not unit.tips:
            return SuccessResponse(
                data={
                    "deleted": False,
                    "message": "Unidade n√£o possui TIPS para deletar"
                },
                message="Nenhuma estrat√©gia TIPS encontrada para deletar"
            )
        
        # Obter estrat√©gia para remover da lista
        strategy_to_remove = unit.tips.get("strategy")
        
        # Deletar TIPS (setar como None)
        await hierarchical_db.update_unit_content(unit_id, "tips", None)
        
        # Remover da lista de estrat√©gias usadas
        if strategy_to_remove and unit.strategies_used:
            updated_strategies = [s for s in unit.strategies_used if s != strategy_to_remove]
            await hierarchical_db.update_unit_content(unit_id, "strategies_used", updated_strategies)
        
        # Ajustar status se necess√°rio
        if unit.status.value in ["assessments_pending", "completed"]:
            await hierarchical_db.update_unit_status(unit_id, "content_pending")
        
        # Log da dele√ß√£o
        await audit_logger_instance.log_event(
            event_type=AuditEventType.UNIT_UPDATED,
            request=request,
            additional_data={
                "update_type": "tips_deleted",
                "unit_id": unit_id,
                "previous_strategy": strategy_to_remove
            }
        )
        
        return SuccessResponse(
            data={
                "deleted": True,
                "previous_strategy": strategy_to_remove,
                "new_status": "content_pending"
            },
            message="Estrat√©gias TIPS deletadas com sucesso",
            hierarchy_info={
                "course_id": unit.course_id,
                "book_id": unit.book_id,
                "unit_id": unit_id,
                "sequence": unit.sequence_order
            },
            next_suggested_actions=[
                "Regenerar estrat√©gias TIPS",
                f"POST /api/v2/units/{unit_id}/tips"
            ]
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro ao deletar TIPS da unidade {unit_id}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro interno: {str(e)}"
        )


@router.get("/units/{unit_id}/tips/analysis", response_model=SuccessResponse)
async def analyze_unit_tips(unit_id: str, request: Request):
    """Analisar qualidade e adequa√ß√£o das estrat√©gias TIPS da unidade."""
    try:
        logger.info(f"Analisando TIPS da unidade: {unit_id}")
        
        # Buscar unidade
        unit = await hierarchical_db.get_unit(unit_id)
        if not unit:
            raise HTTPException(
                status_code=404,
                detail=f"Unidade {unit_id} n√£o encontrada"
            )
        
        # Verificar se √© unidade lexical
        if unit.unit_type.value != "lexical_unit":
            raise HTTPException(
                status_code=400,
                detail="An√°lise de TIPS √© apenas para unidades lexicais"
            )
        
        # Verificar se possui TIPS
        if not unit.tips:
            raise HTTPException(
                status_code=400,
                detail="Unidade n√£o possui TIPS para analisar"
            )
        
        # Buscar contexto RAG para compara√ß√£o
        used_strategies = await hierarchical_db.get_used_strategies(
            unit.course_id, unit.book_id, unit.sequence_order
        )
        
        # Analisar TIPS
        tips_data = unit.tips
        
        analysis = {
            "strategy_analysis": _analyze_strategy_selection(tips_data, used_strategies),
            "content_quality": _analyze_tips_content_quality(tips_data),
            "vocabulary_integration": _analyze_vocabulary_integration(tips_data, unit.vocabulary),
            "pedagogical_effectiveness": _analyze_pedagogical_effectiveness(tips_data, unit.cefr_level.value),
            "phonetic_analysis": _analyze_phonetic_components(tips_data),
            "contextual_relevance": _analyze_contextual_relevance(tips_data, unit)
        }
        
        # Gerar recomenda√ß√µes
        recommendations = _generate_tips_recommendations(analysis, unit)
        
        return SuccessResponse(
            data={
                "analysis": analysis,
                "recommendations": recommendations,
                "summary": {
                    "strategy_used": tips_data.get("strategy"),
                    "overall_quality": _calculate_tips_quality(analysis),
                    "vocabulary_coverage": len(tips_data.get("vocabulary_coverage", [])),
                    "pedagogical_score": analysis["pedagogical_effectiveness"].get("effectiveness_score", 0),
                    "needs_improvement": len(recommendations) > 0
                }
            },
            message=f"An√°lise das estrat√©gias TIPS da unidade '{unit.title}'",
            hierarchy_info={
                "course_id": unit.course_id,
                "book_id": unit.book_id,
                "unit_id": unit_id,
                "sequence": unit.sequence_order
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro ao analisar TIPS da unidade {unit_id}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro interno: {str(e)}"
        )


@router.get("/tips/strategies", response_model=SuccessResponse)
async def get_tips_strategies_info(request: Request):
    """Obter informa√ß√µes sobre as 6 estrat√©gias TIPS dispon√≠veis."""
    try:
        strategies_info = {
            "afixacao": {
                "name": "TIP 1: Afixa√ß√£o",
                "description": "Ensino atrav√©s de prefixos e sufixos",
                "when_to_use": "Vocabul√°rio com padr√µes morfol√≥gicos claros",
                "examples": ["unsafe, illegal, teacher, quickly"],
                "benefit": "Expans√£o sistem√°tica de vocabul√°rio",
                "detection_criteria": "Palavras com prefixos/sufixos comuns",
                "cefr_levels": ["A2", "B1", "B2", "C1"],
                "phonetic_focus": "Stress patterns in derived words"
            },
            "substantivos_compostos": {
                "name": "TIP 2: Substantivos Compostos",
                "description": "Agrupamento de palavras compostas por tema",
                "when_to_use": "Palavras compostas do mesmo campo sem√¢ntico",
                "examples": ["telephone ‚Üí cellphone, telephone booth, telephone number"],
                "benefit": "Agrupamento tem√°tico eficiente",
                "detection_criteria": "Fam√≠lias de palavras compostas",
                "cefr_levels": ["A1", "A2", "B1"],
                "phonetic_focus": "Compound stress patterns"
            },
            "colocacoes": {
                "name": "TIP 3: Coloca√ß√µes",
                "description": "Combina√ß√µes naturais de palavras",
                "when_to_use": "Combina√ß√µes verbo+substantivo, adjetivo+substantivo",
                "examples": ["take a holiday, heavy rain, arrive at"],
                "benefit": "Naturalidade na comunica√ß√£o",
                "detection_criteria": "Padr√µes de coocorr√™ncia",
                "cefr_levels": ["B1", "B2", "C1", "C2"],
                "phonetic_focus": "Rhythm in collocations"
            },
            "expressoes_fixas": {
                "name": "TIP 4: Express√µes Fixas",
                "description": "Frases cristalizadas e f√≥rmulas fixas",
                "when_to_use": "Frases que n√£o podem ser alteradas",
                "examples": ["to tell you the truth, it's up to you"],
                "benefit": "Comunica√ß√£o funcional autom√°tica",
                "detection_criteria": "Express√µes n√£o alter√°veis",
                "cefr_levels": ["A2", "B1", "B2"],
                "phonetic_focus": "Intonation patterns in fixed expressions"
            },
            "idiomas": {
                "name": "TIP 5: Idiomas",
                "description": "Express√µes com significado figurativo",
                "when_to_use": "Express√µes idiom√°ticas e metaf√≥ricas",
                "examples": ["under the weather, green fingers"],
                "benefit": "Compreens√£o cultural e flu√™ncia",
                "detection_criteria": "Significado n√£o-literal",
                "cefr_levels": ["B2", "C1", "C2"],
                "phonetic_focus": "Connected speech in idioms"
            },
            "chunks": {
                "name": "TIP 6: Chunks",
                "description": "Blocos funcionais de linguagem",
                "when_to_use": "Unidades funcionais completas",
                "examples": ["I'd like to..., How about...?, Let me think"],
                "benefit": "Flu√™ncia autom√°tica e mem√≥ria de longo prazo",
                "detection_criteria": "Unidades funcionais completas",
                "cefr_levels": ["A1", "A2", "B1", "B2"],
                "phonetic_focus": "Rhythm and stress in chunks"
            }
        }
        
        return SuccessResponse(
            data={
                "strategies": strategies_info,
                "selection_logic": {
                    "total_available": 6,
                    "selection_criteria": [
                        "Vocabulary patterns in the unit",
                        "CEFR level appropriateness",
                        "Balance with previous strategies used",
                        "Phonetic complexity considerations",
                        "Contextual relevance to unit theme"
                    ]
                },
                "ivo_v2_approach": {
                    "intelligent_selection": "RAG-based strategy selection",
                    "variety_maintenance": "Avoid overuse of same strategy",
                    "vocabulary_integration": "Strategy aligns with unit vocabulary",
                    "phonetic_awareness": "Include pronunciation guidance"
                }
            },
            message="Informa√ß√µes sobre as 6 estrat√©gias TIPS do IVO V2"
        )
        
    except Exception as e:
        logger.error(f"Erro ao obter informa√ß√µes das estrat√©gias TIPS: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro interno: {str(e)}"
        )


# =============================================================================
# HELPER FUNCTIONS PARA TIPS.PY
# =============================================================================

def _determine_progression_level(sequence_order: int) -> str:
    """Determinar n√≠vel de progress√£o baseado na sequ√™ncia."""
    if sequence_order <= 3:
        return "basic_tips"
    elif sequence_order <= 7:
        return "intermediate_tips"
    else:
        return "advanced_tips"


def _analyze_strategy_selection(tips_data: Dict[str, Any], used_strategies: List[str]) -> Dict[str, Any]:
    """Analisar adequa√ß√£o da sele√ß√£o da estrat√©gia."""
    current_strategy = tips_data.get("strategy")
    strategy_count = used_strategies.count(current_strategy) if current_strategy else 0
    
    return {
        "selected_strategy": current_strategy,
        "usage_frequency": strategy_count,
        "is_overused": strategy_count > 2,  # M√°ximo 2 vezes por book
        "selection_rationale": tips_data.get("selection_rationale", ""),
        "complementary_strategies": tips_data.get("complementary_strategies", []),
        "strategy_diversity_score": len(set(used_strategies)) / 6 if used_strategies else 0
    }


def _analyze_tips_content_quality(tips_data: Dict[str, Any]) -> Dict[str, Any]:
    """Analisar qualidade do conte√∫do das TIPS."""
    examples = tips_data.get("examples", [])
    practice_suggestions = tips_data.get("practice_suggestions", [])
    
    return {
        "examples_count": len(examples),
        "practice_suggestions_count": len(practice_suggestions),
        "memory_techniques_count": len(tips_data.get("memory_techniques", [])),
        "phonetic_focus": tips_data.get("phonetic_focus", []),
        "pronunciation_tips": tips_data.get("pronunciation_tips", []),
        "content_quality_score": (len(examples) + len(practice_suggestions)) / 10  # Exemplo de pontua√ß√£o
    }


def _analyze_vocabulary_integration(tips_data: Dict[str, Any], unit_vocabulary: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    """Analisar integra√ß√£o com vocabul√°rio da unidade."""
    vocabulary_coverage = tips_data.get("vocabulary_coverage", [])
    
    if not unit_vocabulary or not unit_vocabulary.get("items"):
        return {
            "coverage_percentage": 0,
            "words_covered": 0,
            "total_vocabulary": 0,
            "integration_score": 0
        }
    
    unit_words = [item.get("word", "").lower() for item in unit_vocabulary.get("items", [])]
    covered_words = [word.lower() for word in vocabulary_coverage]
    
    words_covered = len([word for word in covered_words if word in unit_words])
    coverage_percentage = (words_covered / len(unit_words)) * 100 if unit_words else 0
    
    return {
        "coverage_percentage": coverage_percentage,
        "words_covered": words_covered,
        "total_vocabulary": len(unit_words),
        "integration_score": coverage_percentage / 100,
        "uncovered_words": [word for word in unit_words if word not in covered_words][:5]
    }


def _analyze_pedagogical_effectiveness(tips_data: Dict[str, Any], cefr_level: str) -> Dict[str, Any]:
    """Analisar efic√°cia pedag√≥gica da estrat√©gia."""
    strategy = tips_data.get("strategy", "")
    
    # Mapear efic√°cia por estrat√©gia e n√≠vel
    strategy_effectiveness = {
        "afixacao": {"A1": 0.6, "A2": 0.8, "B1": 0.9, "B2": 0.8, "C1": 0.7, "C2": 0.6},
        "substantivos_compostos": {"A1": 0.9, "A2": 0.9, "B1": 0.8, "B2": 0.6, "C1": 0.5, "C2": 0.4},
        "colocacoes": {"A1": 0.3, "A2": 0.5, "B1": 0.8, "B2": 0.9, "C1": 0.9, "C2": 0.8},
        "expressoes_fixas": {"A1": 0.5, "A2": 0.8, "B1": 0.8, "B2": 0.7, "C1": 0.6, "C2": 0.5},
        "idiomas": {"A1": 0.2, "A2": 0.3, "B1": 0.5, "B2": 0.8, "C1": 0.9, "C2": 0.9},
        "chunks": {"A1": 0.9, "A2": 0.9, "B1": 0.8, "B2": 0.7, "C1": 0.6, "C2": 0.5}
    }
    
    effectiveness_score = strategy_effectiveness.get(strategy, {}).get(cefr_level, 0.7)
    
    return {
        "strategy": strategy,
        "cefr_level": cefr_level,
        "effectiveness_score": effectiveness_score,
        "is_appropriate": effectiveness_score >= 0.7,
        "recommendations": _get_effectiveness_recommendations(strategy, cefr_level, effectiveness_score)
    }


def _analyze_phonetic_components(tips_data: Dict[str, Any]) -> Dict[str, Any]:
    """Analisar componentes fon√©ticos das TIPS."""
    phonetic_focus = tips_data.get("phonetic_focus", [])
    pronunciation_tips = tips_data.get("pronunciation_tips", [])
    
    return {
        "has_phonetic_focus": len(phonetic_focus) > 0,
        "phonetic_elements": phonetic_focus,
        "pronunciation_guidance": len(pronunciation_tips) > 0,
        "pronunciation_tips_count": len(pronunciation_tips),
        "phonetic_integration_score": (len(phonetic_focus) + len(pronunciation_tips)) / 10
    }


def _analyze_contextual_relevance(tips_data: Dict[str, Any], unit) -> Dict[str, Any]:
    """Analisar relev√¢ncia contextual da estrat√©gia."""
    strategy = tips_data.get("strategy", "")
    unit_context = unit.context or ""
    unit_title = unit.title or ""
    
    # An√°lise de palavras-chave do contexto
    context_keywords = unit_context.lower().split() + unit_title.lower().split()
    strategy_explanation = tips_data.get("explanation", "").lower()
    
    # Verificar alinhamento com contexto
    keyword_matches = sum(1 for keyword in context_keywords if keyword in strategy_explanation)
    context_alignment = keyword_matches / max(len(context_keywords), 1)
    
    return {
        "context_alignment_score": context_alignment,
        "strategy_fits_context": context_alignment > 0.3,
        "unit_context": unit_context,
        "strategy_explanation_length": len(strategy_explanation),
        "keyword_matches": keyword_matches
    }


def _generate_tips_recommendations(analysis: Dict[str, Any], unit) -> List[str]:
    """Gerar recomenda√ß√µes para melhorar TIPS."""
    recommendations = []
    
    # An√°lise de sele√ß√£o de estrat√©gia
    strategy_analysis = analysis["strategy_analysis"]
    if strategy_analysis["is_overused"]:
        recommendations.append(
            f"Estrat√©gia '{strategy_analysis['selected_strategy']}' est√° sendo usada excessivamente "
            f"({strategy_analysis['usage_frequency']} vezes). Considere diversificar."
        )
    
    # An√°lise de qualidade de conte√∫do
    content_quality = analysis["content_quality"]
    if content_quality["examples_count"] < 3:
        recommendations.append(
            f"Poucos exemplos ({content_quality['examples_count']}). Recomendado: pelo menos 3-5 exemplos."
        )
    
    if content_quality["practice_suggestions_count"] < 2:
        recommendations.append(
            "Adicione mais sugest√µes de pr√°tica para refor√ßar a estrat√©gia."
        )
    
    # An√°lise de integra√ß√£o com vocabul√°rio
    vocab_integration = analysis["vocabulary_integration"]
    if vocab_integration["coverage_percentage"] < 50:
        recommendations.append(
            f"Baixa integra√ß√£o com vocabul√°rio da unidade ({vocab_integration['coverage_percentage']:.1f}%). "
            f"Considere incluir mais palavras do vocabul√°rio da unidade."
        )
    
    # An√°lise de efic√°cia pedag√≥gica
    pedagogical = analysis["pedagogical_effectiveness"]
    if not pedagogical["is_appropriate"]:
        recommendations.append(
            f"Estrat√©gia pode n√£o ser a mais adequada para n√≠vel {pedagogical['cefr_level']} "
            f"(efic√°cia: {pedagogical['effectiveness_score']:.1f}). "
            f"Considere: {', '.join(pedagogical['recommendations'])}"
        )
    
    # An√°lise fon√©tica
    phonetic = analysis["phonetic_analysis"]
    if not phonetic["has_phonetic_focus"]:
        recommendations.append(
            "Adicione elementos fon√©ticos para melhorar a pron√∫ncia."
        )
    
    # An√°lise contextual
    contextual = analysis["contextual_relevance"]
    if not contextual["strategy_fits_context"]:
        recommendations.append(
            f"Estrat√©gia tem baixo alinhamento com contexto da unidade "
            f"(score: {contextual['context_alignment_score']:.1f}). "
            f"Adapte explica√ß√µes ao tema da unidade."
        )
    
    # Recomenda√ß√µes espec√≠ficas por estrat√©gia
    strategy = analysis["strategy_analysis"]["selected_strategy"]
    if strategy == "afixacao":
        recommendations.append("Para afixa√ß√£o: foque em padr√µes morfol√≥gicos recorrentes")
    elif strategy == "colocacoes":
        recommendations.append("Para coloca√ß√µes: inclua exerc√≠cios de combina√ß√£o natural")
    elif strategy == "chunks":
        recommendations.append("Para chunks: enfatize uso em situa√ß√µes comunicativas")
    elif strategy == "substantivos_compostos":
        recommendations.append("Para compostos: agrupe por campos sem√¢nticos")
    elif strategy == "expressoes_fixas":
        recommendations.append("Para express√µes fixas: pratique em contextos funcionais")
    elif strategy == "idiomas":
        recommendations.append("Para idiomas: explique o significado cultural")
    
    return recommendations


def _calculate_tips_quality(analysis: Dict[str, Any]) -> float:
    """Calcular qualidade geral das TIPS."""
    try:
        # Componentes da qualidade
        strategy_score = 1.0 if not analysis["strategy_analysis"]["is_overused"] else 0.6
        content_score = min(analysis["content_quality"]["content_quality_score"], 1.0)
        vocab_score = analysis["vocabulary_integration"]["integration_score"]
        pedagogical_score = analysis["pedagogical_effectiveness"]["effectiveness_score"]
        phonetic_score = min(analysis["phonetic_analysis"]["phonetic_integration_score"], 1.0)
        context_score = analysis["contextual_relevance"]["context_alignment_score"]
        
        # M√©dia ponderada
        weights = {
            "strategy": 0.2,
            "content": 0.25,
            "vocabulary": 0.25,
            "pedagogical": 0.15,
            "phonetic": 0.1,
            "context": 0.05
        }
        
        overall_quality = (
            strategy_score * weights["strategy"] +
            content_score * weights["content"] +
            vocab_score * weights["vocabulary"] +
            pedagogical_score * weights["pedagogical"] +
            phonetic_score * weights["phonetic"] +
            context_score * weights["context"]
        )
        
        return round(overall_quality, 2)
        
    except Exception as e:
        logger.warning(f"Erro ao calcular qualidade das TIPS: {str(e)}")
        return 0.7  # Score padr√£o


def _get_effectiveness_recommendations(strategy: str, cefr_level: str, effectiveness_score: float) -> List[str]:
    """Obter recomenda√ß√µes de efic√°cia por estrat√©gia e n√≠vel."""
    recommendations = []
    
    if effectiveness_score < 0.7:
        if strategy == "afixacao" and cefr_level in ["A1", "A2"]:
            recommendations.append("Use prefixos/sufixos mais b√°sicos para iniciantes")
        elif strategy == "colocacoes" and cefr_level in ["A1", "A2"]:
            recommendations.append("Considere chunks ou express√µes fixas para n√≠veis b√°sicos")
        elif strategy == "idiomas" and cefr_level in ["A1", "A2", "B1"]:
            recommendations.append("Idiomas s√£o mais adequados para n√≠veis B2+")
        elif strategy == "substantivos_compostos" and cefr_level in ["B2", "C1", "C2"]:
            recommendations.append("Para n√≠veis avan√ßados, foque em coloca√ß√µes ou idiomas")
        elif strategy == "expressoes_fixas" and cefr_level in ["C1", "C2"]:
            recommendations.append("Para n√≠veis avan√ßados, prefira idiomas ou coloca√ß√µes sofisticadas")
        elif strategy == "chunks" and cefr_level in ["C1", "C2"]:
            recommendations.append("Para n√≠veis avan√ßados, foque em chunks acad√™micos e profissionais")
    
    # Recomenda√ß√µes gerais de melhoria
    if effectiveness_score < 0.5:
        recommendations.append("Considere mudar de estrat√©gia para este n√≠vel")
    elif effectiveness_score < 0.7:
        recommendations.append("Adapte exemplos e exerc√≠cios ao n√≠vel do aluno")
    
    return recommendations


def _get_tips_strategy_info(strategy: str) -> Dict[str, Any]:
    """Obter informa√ß√µes detalhadas sobre uma estrat√©gia TIPS espec√≠fica."""
    strategies_info = {
        "afixacao": {
            "name": "TIP 1: Afixa√ß√£o",
            "description": "Ensino atrav√©s de prefixos e sufixos",
            "morphological_patterns": ["un- (unhappy)", "re- (remake)", "-er (teacher)", "-ly (quickly)"],
            "best_for_levels": ["A2", "B1", "B2"],
            "phonetic_focus": "Stress shift in derived words",
            "memory_technique": "Pattern recognition and word families"
        },
        "substantivos_compostos": {
            "name": "TIP 2: Substantivos Compostos", 
            "description": "Agrupamento tem√°tico de palavras compostas",
            "semantic_fields": ["transport", "technology", "workplace", "home"],
            "best_for_levels": ["A1", "A2", "B1"],
            "phonetic_focus": "Primary stress on first element",
            "memory_technique": "Visual association and semantic grouping"
        },
        "colocacoes": {
            "name": "TIP 3: Coloca√ß√µes",
            "description": "Combina√ß√µes naturais e frequentes de palavras",
            "collocation_types": ["verb+noun", "adjective+noun", "adverb+adjective"],
            "best_for_levels": ["B1", "B2", "C1"],
            "phonetic_focus": "Natural rhythm in multi-word units",
            "memory_technique": "Frequency awareness and natural combinations"
        },
        "expressoes_fixas": {
            "name": "TIP 4: Express√µes Fixas",
            "description": "F√≥rmulas fixas e frases cristalizadas",
            "functions": ["politeness", "discourse_markers", "social_formulas"],
            "best_for_levels": ["A2", "B1", "B2"],
            "phonetic_focus": "Sentence stress and intonation patterns",
            "memory_technique": "Situational memorization and drilling"
        },
        "idiomas": {
            "name": "TIP 5: Idiomas",
            "description": "Express√µes com significado figurativo",
            "categories": ["body_parts", "colors", "animals", "weather"],
            "best_for_levels": ["B2", "C1", "C2"],
            "phonetic_focus": "Connected speech and reduced forms",
            "memory_technique": "Cultural context and image association"
        },
        "chunks": {
            "name": "TIP 6: Chunks",
            "description": "Blocos funcionais para flu√™ncia autom√°tica",
            "chunk_types": ["sentence_starters", "transitions", "functional_phrases"],
            "best_for_levels": ["A1", "A2", "B1"],
            "phonetic_focus": "Rhythm and stress in formulaic sequences",
            "memory_technique": "Repetition and procedural memory"
        }
    }
    
    return strategies_info.get(strategy, {})


def _validate_tips_strategy_selection(
    vocabulary_items: List[Dict[str, Any]], 
    cefr_level: str,
    used_strategies: List[str]
) -> str:
    """Validar e sugerir estrat√©gia TIPS mais adequada."""
    
    # Analisar padr√µes no vocabul√°rio
    has_affixes = any(
        word.get("word", "").startswith(("un", "re", "pre")) or 
        word.get("word", "").endswith(("er", "ly", "tion", "ing"))
        for word in vocabulary_items
    )
    
    has_compounds = any(
        "-" in word.get("word", "") or 
        len(word.get("word", "").split()) > 1
        for word in vocabulary_items
    )
    
    # Contar frequ√™ncia de estrat√©gias j√° usadas
    strategy_counts = {}
    for strategy in used_strategies:
        strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
    
    # L√≥gica de sele√ß√£o baseada no IVO V2 Guide
    if cefr_level in ["A1", "A2"]:
        if has_compounds and strategy_counts.get("substantivos_compostos", 0) < 2:
            return "substantivos_compostos"
        elif strategy_counts.get("chunks", 0) < 2:
            return "chunks"
        else:
            return "expressoes_fixas"
    
    elif cefr_level in ["B1", "B2"]:
        if has_affixes and strategy_counts.get("afixacao", 0) < 2:
            return "afixacao"
        elif strategy_counts.get("colocacoes", 0) < 2:
            return "colocacoes"
        else:
            return "expressoes_fixas"
    
    else:  # C1, C2
        if strategy_counts.get("idiomas", 0) < 2:
            return "idiomas"
        else:
            return "colocacoes"


def _generate_strategy_rationale(
    selected_strategy: str,
    vocabulary_analysis: Dict[str, Any],
    unit_context: Dict[str, Any],
    rag_context: Dict[str, Any]
) -> str:
    """Gerar justificativa para sele√ß√£o da estrat√©gia."""
    
    strategy_info = _get_tips_strategy_info(selected_strategy)
    cefr_level = unit_context.get("cefr_level", "B1")
    
    rationale_parts = []
    
    # Justificativa baseada no n√≠vel CEFR
    if cefr_level in strategy_info.get("best_for_levels", []):
        rationale_parts.append(f"Estrat√©gia adequada para n√≠vel {cefr_level}")
    
    # Justificativa baseada no vocabul√°rio
    vocab_patterns = vocabulary_analysis.get("patterns", [])
    if selected_strategy == "afixacao" and "morphological_patterns" in vocab_patterns:
        rationale_parts.append("Vocabul√°rio apresenta padr√µes morfol√≥gicos claros")
    elif selected_strategy == "substantivos_compostos" and "compound_words" in vocab_patterns:
        rationale_parts.append("Presen√ßa de palavras compostas permite agrupamento tem√°tico")
    elif selected_strategy == "colocacoes" and "natural_combinations" in vocab_patterns:
        rationale_parts.append("Vocabul√°rio permite explorar combina√ß√µes naturais")
    
    # Justificativa baseada no balanceamento RAG
    used_strategies = rag_context.get("used_strategies", [])
    if used_strategies.count(selected_strategy) <= 1:
        rationale_parts.append("Estrat√©gia pouco utilizada no book, promove variedade")
    
    # Justificativa baseada no contexto
    unit_context_text = unit_context.get("context", "")
    if selected_strategy == "chunks" and any(word in unit_context_text.lower() for word in ["communication", "conversation", "speaking"]):
        rationale_parts.append("Contexto comunicativo favorece uso de chunks funcionais")
    
    return ". ".join(rationale_parts) if rationale_parts else f"Estrat√©gia {selected_strategy} selecionada para diversifica√ß√£o pedag√≥gica"


def _extract_phonetic_patterns(vocabulary_items: List[Dict[str, Any]]) -> List[str]:
    """Extrair padr√µes fon√©ticos do vocabul√°rio para foco das TIPS."""
    patterns = []
    
    # Analisar stress patterns
    stress_patterns = []
    for item in vocabulary_items:
        phoneme = item.get("phoneme", "")
        if "Àà" in phoneme:
            stress_patterns.append("primary_stress")
        if "Àå" in phoneme:
            stress_patterns.append("secondary_stress")
    
    if stress_patterns:
        patterns.append("word_stress_patterns")
    
    # Analisar difficult sounds
    difficult_sounds = []
    for item in vocabulary_items:
        phoneme = item.get("phoneme", "")
        if any(sound in phoneme for sound in ["Œ∏", "√∞", " É", " í", "≈ã"]):
            difficult_sounds.append("consonant_clusters")
        if any(sound in phoneme for sound in ["√¶", " å", "…úÀê", "…™…ô", "e…ô"]):
            difficult_sounds.append("vowel_distinctions")
    
    patterns.extend(list(set(difficult_sounds)))
    
    return list(set(patterns))